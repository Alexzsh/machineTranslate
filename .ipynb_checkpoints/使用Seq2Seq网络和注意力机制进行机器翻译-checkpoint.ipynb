{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用Sequence to Sequence网络和注意力机制进行翻译"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本教程我们将会搭建一个网络来将法语翻译成英语。\n",
    "```\n",
    "[KEY: > input, = target, < output]\n",
    "\n",
    "> il est en train de peindre un tableau .\n",
    "= he is painting a picture .\n",
    "< he is painting a picture .\n",
    "\n",
    "> pourquoi ne pas essayer ce vin delicieux ?\n",
    "= why not try that delicious wine ?\n",
    "< why not try that delicious wine ?\n",
    "\n",
    "> elle n est pas poete mais romanciere .\n",
    "= she is not a poet but a novelist .\n",
    "< she not not a poet but a novelist .\n",
    "\n",
    "> vous etes trop maigre .\n",
    "= you re too skinny .\n",
    "< you re all alone .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这可以通过 [Sequence to sequence network](https://arxiv.org/abs/1409.3215) 简单而又强大的 idea来实现，该实现包含两个循环神经网络，它们共同工作从而将一个序列转化为另一个序列：编码器网络将输入压缩成矢量；解码器网络将该矢量展开成新的序列。  \n",
    "\n",
    "![](https://pytorch.org/tutorials/_images/seq2seq.png)\n",
    "<center><strong>图1. Sequence to sequence 网络结构</strong>\n",
    "\n",
    "为了增强模型的表现力，我们同时引入了注意力机制，它使得解码器能够学习到在翻译某个部分的时候该给整个序列多少的注意力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**依赖包**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.cuda.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 加载数据文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本教程的数据文件是几千个英语到法语的翻译句子对。\n",
    "\n",
    ">翻译开源下载地址:[http://www.manythings.org/anki/](http://www.manythings.org/anki/)\n",
    "\n",
    "点击[这里](https://download.pytorch.org/tutorial/data.zip)下载本教程所需的翻译文件。\n",
    "\n",
    "解压到当前目录下，得到一个 `data/eng-fra.txt`文件，该文件每一行是由 tab 分隔开的翻译对:\n",
    "```\n",
    "I am cold.   J'ai froid.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "类似于字符级RNN编码字母序列，我们仍然将源语言的每个单词编码为一个one-hot向量。与语言中可能存在的几十个字符相比，词语的量显然更大，因此编码向量要大得多。我们在这里做个小小的弊，修剪数据----每种语言我们只采用几千个单词。\n",
    "\n",
    "![](https://pytorch.org/tutorials/_images/word-encoding.png)\n",
    "<center><strong>图2. one-hot 编码示例</strong>\n",
    "\n",
    "为了编码词语，我们需要每个单词的唯一索引，以便后续网络的输入和目标的构建。为此我们使用一个名为 `Lang` 的辅助类，它具有 word$\\rightarrow$index (word2index) 和 index$\\rightarrow$word(index2word)两个字典，以及用于稍后替换稀有单词的每个单词的计数(word2count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1:\"EOS\"}\n",
    "        self.n_words = 2 # Count SOS and EOS\n",
    "        \n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "            \n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word]=self.n_words\n",
    "            self.word2count[word]=1\n",
    "            self.index2word[self.n_words]=word\n",
    "            self.n_words +=1\n",
    "        else:\n",
    "            self.word2count[word]+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文件都是Unicode编码的，我们需要简单得将字符转化为ASCII编码，全部转化为小写字母，并修剪大部分标点符号。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to \n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicode2Ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicode2Ascii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取数据，我们将文件分割成行，进一步分割成句子对。文件是 English$\\rightarrow$其他语言 ，所以这里加上一个 `reverse` 参数，可以用来获取 其他语言$\\rightarrow$英语 的翻译对。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse = False):\n",
    "    print(\"Reading lines...\")\n",
    "    \n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt'%(lang1,lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "        \n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "    \n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于样本句子很多，而我们想加速训练。我们会将数据集修剪成相对简短的句子。这里的最大长度是10(包括结束标点)，同时我们会过滤出 \"我是\",\"他是\" 这种形式的句子(别忘记之前忽略的撇号,比如 \"I'm\" 这种形式)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am\", \"i m\",\n",
    "    \"he is\", \"he s\",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re\",\n",
    "    \"we are\", \"we re\",\n",
    "    \"they are\", \"they re\"\n",
    ")\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' '))< MAX_LENGTH and \\\n",
    "           len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "           p[1].startswith(eng_prefixes)\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完整的数据准备流程如下：\n",
    "- 读取文本文件，按行分割，再将每行分割成语句对\n",
    "- 归一化文本，过滤内容和长度\n",
    "- 根据滤出的句子对创建词语列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 11893 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4920\n",
      "eng 3228\n",
      "['je ne suis pas assez bon pour vous .', 'i m not good enough for you .']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng','fra', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Seq2Seq 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "循环神经网络对一个序列操作，然后将其输出作为下一个子操作的输入。\n",
    "\n",
    "一个 Sequence to Sequence，或者叫 seq2seq 网络，又或者叫 编码-解码网络，包含了两个RNN部分：编码器和解码器。编码器网络将输入序列转化为单个向量，解码器读取这个向量，将其转化为序列输出。**图1** 展示了这个结构。这里我们回顾下图1：\n",
    "\n",
    "![](https://pytorch.org/tutorials/_images/seq2seq.png)\n",
    "<center><strong>图1. Sequence to sequence 网络结构</strong>\n",
    "\n",
    "与使用单个RNN的序列预测不同(单个RNN序列预测的每个输入都对应一个输出), seq2seq模型使得我们能从序列的长度和顺序中解放出来，这使得其能够成为两种语言之间相互转换的理想选择。 \n",
    "\n",
    "考虑一个句子对:\n",
    "```\n",
    "Je ne suis pas le char noir     I am not the black cat\n",
    "```\n",
    "输入句子中很多单词可以直接翻译到对应的输出句子中，但是可能会有细微的顺序变动，比如 `chat noir` 和 `black cat`。此外由于`ne/pas`结构，输入句子比输出句子多一个单词。直接通过翻译输入词语的产生正确的翻译句子是很困难的。\n",
    "\n",
    "\n",
    "使用seq2seq模型，编码器创建单个向量，在理想情况下，将输入序列的“语义”编码为单个向量---代表句子的某些N维空间中的单个点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 编码器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seq2seq网络的编码器是一个RNN，它通过**阅读**输入句子的每个单词，来生成一些值。对每一个输入单词，编码器输出一个向量和一个隐藏状态，并且使用这个隐藏状态作为下一个单词的输入。\n",
    "![](https://pytorch.org/tutorials/_images/encoder-network.png)\n",
    "<center><strong>图3. 编码器结构</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        \n",
    "    def forward(self,input, hidden):\n",
    "        embedded = self.embedding(input).view(1,1,-1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1,1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 解码器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解码器使用编码器输出的向量作为输入，输出一串单词，从而完成翻译。\n",
    "\n",
    "#### 简单的解码器\n",
    "在最简单的解码器中我们仅仅使用编码器最后一步的输出作为输入。这个最后一步的输出有时候被称为**(上下文向量)context vector** 因为它编码了整个文本序列。这个上下文向量被用作解码器的初始隐藏状态。\n",
    "\n",
    "在解码的每一步，解码器接受一个词语和一个隐藏状态。初始的输入词语是单词开始标记`<SOS>`，初始隐藏状态是上文提到的上下文向量。\n",
    "![](https://pytorch.org/tutorials/_images/decoder-network.png)\n",
    "<center><strong>图4. 简单的解码器结构</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self,input, hidden):\n",
    "        output = self.embedding(input).view(1,1,-1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1,1, self.hidden_size, device=device)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我鼓励你训练和观察这个模型的结果，但为了节省空间，我们将\"直捣黄龙\"并引入注意机制。\n",
    "\n",
    "#### 注意力的解码器\n",
    "\n",
    "如果仅仅是在编码器和解码器之间传递上下文向量， 对单个向量来说，表达整个句子是很困难的。\n",
    "\n",
    "注意力机制允许解码器在解码的每一步获得一个关于原始句子的注意量(即是说，这一步的翻译需要在原始句子的不同部分投入多少的注意力)。首先我们计算一个注意力权重的集合。这些权重将和编码器的输出向量相乘来获得一个权重敏感的输出。这个步骤的结果(在代码里为`attn_applied`)应包含有关输入序列特定部分的信息，从而帮助解码器选择正确的输出字。\n",
    "\n",
    "![](https://i.imgur.com/1152PYf.png)\n",
    "<center><strong>图5. 注意力结构</strong>\n",
    "\n",
    "使用一个前馈层 `attn` 来计算注意力权重，它使用解码器的输入和隐藏状态作为输入。因为训练数据中的句子长短不一，因此要创建和训练这一层，就必须选择最长的句子长度。最大长度的句子将使用所有注意力量，而较短的句子将仅使用前几个。\n",
    "\n",
    "![](https://pytorch.org/tutorials/_images/attention-decoder-network.png)\n",
    "<center><strong>图6. 注意力解码器结构</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self,hidden_size,output_size, dropout_p=0.1, max_length = MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size*2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size*2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1,1,-1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat([embedded[0],hidden[0]],1)),dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        output = torch.cat([embedded[0], attn_applied[0]],1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        \n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        \n",
    "        output = F.log_softmax(self.out(output[0]),dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1,1, self.hidden_size, device=device)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过使用相对位置方法，还有其他形式的注意力可以解决长度限制问题。参考 [Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/abs/1508.04025)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 准备训练数据\n",
    "\n",
    "对每个训练样本对，我们需要一个输入张量(输入句子中每个词语在词典中的位置)和目标张量(目标句子中每个词语在词典中的的位置)。在创建这些向量的同时，我们给两个都句子都加上 EOS 作为结束词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1,1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 训练模型\n",
    "\n",
    "我们将句子输入到编码器网络中，同时跟踪其每一步的输出和最后一步的隐藏状态。然后解码器网络接受一个 `<SOS>` 作为第一步的输入，编码器最后一步的隐藏状态作为其初始隐藏状态。\n",
    "\n",
    "这里有个选择问题：关于解码器的每一步，我们到底使用目标字母直接输入，还是使用前一步的网络预测结果作为输入？\n",
    "\n",
    "**Teacher forcing** 概念：使用真实目标输出作为下一个输入，而不是使用解码器的预测作为下一个输入。使用**teacher forcing**可以使网络更快地收敛，但是当受过训练的网络被运用时，它可能表现出不稳定性。\n",
    "\n",
    "你可以观察下网络的输出，读起来看似语法相关，但是实际上远离正确的翻译---直觉上网络学到了如何表示输出语法，并且一旦'Teacher'告诉它前面几个单词，它就会“提取”含义，但它还没有正确地学习如何从翻译中创建句子。  \n",
    "\n",
    "由于PyTorch的autograd为我们提供了自由度，我们可以随意选择使用teacher forcing或不使用通过简单的if语句。将teacher_forcing_ratio来控制使用的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length = MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    \n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei]=encoder_output[0,0]\n",
    "        \n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "    \n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the targer as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss+=criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]   # Teacher forcing\n",
    "            \n",
    "    else:\n",
    "        # Without teaching forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach() # detach from history as input\n",
    "            \n",
    "            loss+=criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item()==EOS_token:\n",
    "                break\n",
    "                \n",
    "    loss.backward()\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是一个辅助函数，用于打印经过的时间和估计的剩余时间，通过给定的当前时间和进度％。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完整的训练流程如下：\n",
    "- 计时器打开\n",
    "- 初始化优化器和评估函数\n",
    "- 创建训练对\n",
    "- 开始跟踪损失\n",
    "\n",
    "然后我们会多次调用 `train` ，间断打印进度（例子的百分比，到目前为止的时间，估计的时间）和平均损失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=1000, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses=[]\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0   # Reset every plot_every\n",
    "    \n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)]\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    for iter in range(1, n_iters+1):\n",
    "        training_pair = training_pairs[iter-1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        \n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        \n",
    "        print_loss_total+=loss\n",
    "        plot_loss_total+=loss\n",
    "        \n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 可视化结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "评估与训练大致相同，但没有目标，因此我们只需将解码器的预测反馈给每个步骤。每次它预测一个单词时我们都会将它添加到输出字符串中，如果它预测了EOS标记，我们就会停止。我们还存储解码器的注意力输出以供稍后显示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 我们可以从训练集中评估随机句子并打印输入，目标和输出以做出一些主观质量判断：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 训练与评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有了所有这些辅助函数（它看起来像是额外的工作，但它使得更容易运行多个实验）我们实际上可以初始化网络并开始训练。 \n",
    "\n",
    "请记住，输入句子被严重过滤。对于这个小数据集，我们可以使用256个隐藏节点和单个GRU层的相对较小的网络。在MacBook CPU上大约40分钟后，我们将得到一些合理的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'EncoderRNN' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-b8cb29ad6fbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mencoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_lang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mattn_decoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttnDecoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/user/.virtualenvs/py3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    396\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 398\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EncoderRNN' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateRandomly(encoder1,  attn_decoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 可视化注意力\n",
    "\n",
    "注意机制的一个很有用的特性是其高度可解释的输出。因为它用于对输入序列的特定编码器输出进行加权，所以我们可以想象在每个时间步长看网络最关注的位置。\n",
    "\n",
    "你可以简单地运行`plt.matshow(attentions)` 以将注意力输出显示为矩阵，其中列是输入步骤，行是输出步骤："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "output_words, attentions = evaluate(\n",
    "    encoder1, attn_decoder1, \"je suis trop froid .\")\n",
    "plt.matshow(attentions.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了更好地展示结果，我们给轴添加上标签："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with color bar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "    \n",
    "    # Set up axes\n",
    "    ax.set_xticklabels(['']+input_sentence.split(' ')+['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels(['']+output_words)\n",
    "    \n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder1, attn_decoder1, input_sentence)\n",
    "    print('input = ', input_sentence)\n",
    "    print('output = ', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions)\n",
    "    \n",
    "evaluateAndShowAttention(\"elle a cinq ans de moins que moi .\")\n",
    "\n",
    "evaluateAndShowAttention(\"elle est trop petit .\")\n",
    "\n",
    "evaluateAndShowAttention(\"je ne crains pas de mourir .\")\n",
    "\n",
    "evaluateAndShowAttention(\"c est un jeune directeur plein de talent .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
